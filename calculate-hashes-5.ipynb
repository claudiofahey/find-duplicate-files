{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate hashes of all files.\n",
    "\n",
    "Caches calulated hashes in a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import hashlib\n",
    "from pathlib import Path, PurePath, PurePosixPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('M:\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_listing = []\n",
    "for filename in glob.iglob('**', recursive=True):\n",
    "    path = Path(filename)\n",
    "    if path.is_file():\n",
    "        filename = path.as_posix()\n",
    "        stat = path.stat()\n",
    "        filesize = stat.st_size\n",
    "        mtime = int(stat.st_mtime)\n",
    "        #print((filename, filesize, mtime))\n",
    "        file_listing += [(filename, filesize, mtime)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_listing_df = pd.DataFrame(file_listing, columns=['filename', 'filesize', 'mtime'])\n",
    "file_listing_df\n",
    "# file_listing_df = file_listing_df.set_index(['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_listing_df['ext'] = file_listing_df.filename.apply(lambda f: os.path.splitext(f)[1].lower())\n",
    "file_listing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exts = [\n",
    "    '.avi',\n",
    "    '.bmp',\n",
    "    '.gif',\n",
    "    '.jpeg',\n",
    "    '.jpg',\n",
    "    '.m4a',\n",
    "    '.m4p',\n",
    "    '.m4v',\n",
    "    '.mov',\n",
    "    '.mp2',\n",
    "    '.mp3',\n",
    "    '.mp4',\n",
    "    '.pcd',\n",
    "    '.png',\n",
    "    '.tif',\n",
    "    '.vob',\n",
    "    '.wma',\n",
    "    '.wmf',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_listing_df = file_listing_df[file_listing_df.ext.isin(exts)]\n",
    "file_listing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_hash_cache_df = pd.read_json('file_hash_cache.json', orient='records', lines=True)\n",
    "file_hash_cache_df = file_hash_cache_df.set_index(['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_cache_df = file_listing_df.set_index(['filename']).join(file_hash_cache_df, how='left', rsuffix='_cached')\n",
    "with_cache_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_hash_df = with_cache_df[with_cache_df.hash.isna()].copy()\n",
    "need_hash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_cache_df.filesize.sum() * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_hash_df.filesize.sum() * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_file_hash(filename):\n",
    "    file_hash = hashlib.sha256()\n",
    "    with open(filename, 'rb') as f:\n",
    "        while True:\n",
    "            chunk = f.read(64*1024)\n",
    "            if not chunk: break\n",
    "            file_hash.update(chunk)\n",
    "    return file_hash.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "need_hash_df['hash'] = Parallel(n_jobs=-1)(delayed(calc_file_hash)(filename) for filename in need_hash_df.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_hash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_hash_df = with_cache_df.join(need_hash_df[['hash']], how='left', lsuffix='_cached')\n",
    "with_hash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_hash_df.loc[with_hash_df.hash.isna(), 'hash'] = with_hash_df.loc[with_hash_df.hash.isna(), 'hash_cached']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_hash_df = with_hash_df[['filesize','mtime','hash']].reset_index()\n",
    "with_hash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_hash_df.to_json('file_hash_cache.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
